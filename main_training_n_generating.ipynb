{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains all generative model classes and a general script for training them. The same function samples from each generative model and both saves and plots the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Type\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import sbibm\n",
    "import seaborn as sns\n",
    "import bayesflow as bf\n",
    "import bayesflow.benchmarks.lotka_volterra as lotka_volterra\n",
    "import bayesflow.benchmarks.sir as SIR\n",
    "import nflows.nn.nets as nets\n",
    "from nflows.transforms.base import CompositeTransform\n",
    "from nflows.flows.base import Flow\n",
    "from nflows.distributions.normal import StandardNormal\n",
    "from nflows.transforms.autoregressive import MaskedAffineAutoregressiveTransform   # MAF \n",
    "from nflows.transforms import PiecewiseRationalQuadraticCouplingTransform #NSF\n",
    "from nflows.transforms import Permutation\n",
    "from generate_dataset import generate_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cVAE Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder for q(z | theta, y).\n",
    "    Inputs: theta (parameter) and y (observation), concatenated.\n",
    "    Outputs: mu and log_var for latent variable z (dimension z_dim).\n",
    "    \"\"\"\n",
    "    def __init__(self, theta_dim, y_dim, z_dim, hidden_dim: list):\n",
    "        super(Encoder, self).__init__()\n",
    "        hidden_dim.insert(0, theta_dim + y_dim) #Inserting initial amount of neurons\n",
    "        layers = []\n",
    "        \n",
    "        #Converting list of neurons to pytorch architecture\n",
    "        for i in range(len(hidden_dim) - 1):\n",
    "            layers.append(nn.Linear(hidden_dim[i], hidden_dim[i + 1]))\n",
    "            layers.append(nn.LeakyReLU(0.1))\n",
    "            layers.append(nn.LayerNorm(hidden_dim[i + 1]))\n",
    "\n",
    "        mu_layers = [nn.Linear(hidden_dim[-1], z_dim)]\n",
    "        log_var_layers = [nn.Linear(hidden_dim[-1], z_dim)]\n",
    "\n",
    "        #Defining layers from lists\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        self.mu = mu_layers[0]\n",
    "        self.log_var = log_var_layers[0]\n",
    "\n",
    "        #Storing layer info for printing\n",
    "        self.layers = layers\n",
    "        self.out_layers = mu_layers\n",
    "\n",
    "    def forward(self, theta, y):\n",
    "        inp = torch.cat([theta, y], dim=1)\n",
    "        h = self.net(inp)\n",
    "        return self.mu(h), self.log_var(h)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder for p(theta | z, y).\n",
    "    Inputs: z (latent) and y (observation), concatenated.\n",
    "    Outputs: mu and log_var for theta (reconstruction).\n",
    "    \"\"\"\n",
    "    def __init__(self, z_dim, y_dim, theta_dim, hidden_dim: list):\n",
    "        super(Decoder, self).__init__()\n",
    "        hidden_dim.insert(0, z_dim + y_dim)\n",
    "        layers = []\n",
    "        \n",
    "        for i in range(len(hidden_dim) - 1):\n",
    "            layers.append(nn.Linear(hidden_dim[i], hidden_dim[i + 1]))\n",
    "            layers.append(nn.LeakyReLU(0.1))\n",
    "            layers.append(nn.LayerNorm(hidden_dim[i + 1]))\n",
    "\n",
    "        mu_layers = [nn.Linear(hidden_dim[-1], theta_dim)]\n",
    "        log_var_layers = [nn.Linear(hidden_dim[-1], theta_dim)]\n",
    "\n",
    "        #Defining layers from lists\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        self.mu = mu_layers[0]\n",
    "        self.log_var = log_var_layers[0]\n",
    "\n",
    "        #Storing layer info\n",
    "        self.layers = layers\n",
    "        self.out_layers = mu_layers\n",
    "\n",
    "    def forward(self, z, y):\n",
    "        inp = torch.cat([z, y], dim=1)\n",
    "        h = self.net(inp)\n",
    "        return self.mu(h), self.log_var(h)\n",
    "    \n",
    "\n",
    "class PriorNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Prior network for p(z | y).\n",
    "    Input: y (observation).\n",
    "    Outputs: mu and log_var for latent variable z (dimension z_dim).\n",
    "    \"\"\"\n",
    "    def __init__(self, y_dim, z_dim, hidden_dim: list):\n",
    "        super(PriorNetwork, self).__init__()\n",
    "        \n",
    "        hidden_dim.insert(0, y_dim)\n",
    "        layers = []\n",
    "        \n",
    "        for i in range(len(hidden_dim) - 1):\n",
    "            layers.append(nn.Linear(hidden_dim[i], hidden_dim[i + 1]))\n",
    "            layers.append(nn.LeakyReLU(0.1))\n",
    "            layers.append(nn.LayerNorm(hidden_dim[i + 1]))\n",
    "\n",
    "        mu_layers = [nn.Linear(hidden_dim[-1], z_dim)]\n",
    "        log_var_layers = [nn.Linear(hidden_dim[-1], z_dim)]\n",
    "\n",
    "        #Defining layers from lists\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        self.mu = mu_layers[0]\n",
    "        self.log_var = log_var_layers[0]\n",
    "\n",
    "        #Storing layer info\n",
    "        self.layers = layers\n",
    "        self.out_layers = mu_layers\n",
    "\n",
    "    def forward(self, y):\n",
    "        h = self.net(y)\n",
    "        return self.mu(h), self.log_var(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent cVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Independent_cVAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Complete Conditional VAE:\n",
    "      - Encoder:   q(z | theta, y)\n",
    "      - Prior:     p(z | y)\n",
    "      - Decoder:   p(theta | z, y)\n",
    "\n",
    "    Parameters:\n",
    "      theta: parameter of interest (dimension theta_dim)\n",
    "      y: observation (dimension y_dim)\n",
    "      z: latent variable (dimension z_dim)\n",
    "    \"\"\"\n",
    "    def __init__(self, theta_dim: int, y_dim: int, z_dim: int,\n",
    "                 encoder_hidden_dim: list,\n",
    "                 decoder_hidden_dim: list,\n",
    "                 init_type='kaiming_normal'):\n",
    "        super(Independent_cVAE, self).__init__()\n",
    "        self.encoder = Encoder(theta_dim, y_dim, z_dim, hidden_dim=encoder_hidden_dim)\n",
    "        self.decoder = Decoder(z_dim, y_dim, theta_dim, hidden_dim=decoder_hidden_dim)\n",
    "        self._init_weights(init_type)\n",
    "\n",
    "        self.theta_dim = theta_dim\n",
    "        self.y_dim = y_dim\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, theta, y):\n",
    "        # Encoder: q(z | theta, y)\n",
    "        mu_q, log_var_q = self.encoder(theta, y)\n",
    "        # Sample latent variable z ~ q(z | theta, y)\n",
    "        z = self.reparameterize(mu_q, log_var_q)\n",
    "        # Decoder: p(theta | z, y)\n",
    "        mu_theta, log_var_theta = self.decoder(z, y)\n",
    "        return theta, mu_q, log_var_q, mu_theta, log_var_theta\n",
    "\n",
    "    def loss_function(self, theta, mu_q, log_var_q, mu_theta, log_var_theta, beta):\n",
    "        # Convert log-variances to variances\n",
    "        var_q = torch.exp(log_var_q)\n",
    "        var_theta = torch.exp(log_var_theta)\n",
    "\n",
    "        # KL divergence between q(z|theta,y)=N(mu_q,var_q) and p(z)=N(0,I)\n",
    "        KL = beta * -0.5 * torch.mean(\n",
    "            log_var_q - torch.pow(mu_q,2) - var_q + 1\n",
    "        )\n",
    "\n",
    "        # Gaussian Negative Log-Likelihood for theta reconstruction (ignoring constants)\n",
    "        NLL = torch.mean(\n",
    "            log_var_theta + torch.pow(theta - mu_theta, 2) / var_theta\n",
    "        )\n",
    "        return KL, NLL, KL + NLL\n",
    "\n",
    "    def sample(self, num_samples, y):\n",
    "        # Set the model to evaluation mode\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            # Ensure y is a float tensor and repeat for num_samples\n",
    "            y = torch.as_tensor(y, dtype=torch.float32).repeat(num_samples, 1)\n",
    "            z_dim = self.encoder.mu.out_features  # Get latent space dimension\n",
    "            z = torch.randn(num_samples, z_dim, device=y.device)\n",
    "            # Decode to get theta reconstruction parameters\n",
    "            mu_theta, log_var_theta = self.decoder(z, y)\n",
    "            # Sample theta using the reparameterization trick\n",
    "            theta = self.reparameterize(mu_theta, log_var_theta)\n",
    "        return theta\n",
    "\n",
    "    def _init_weights(self, init_type):\n",
    "        \"\"\"\n",
    "        Initialize weights in the network with different methods:\n",
    "        - xavier_uniform\n",
    "        - xavier_normal\n",
    "        - kaiming_uniform (He)\n",
    "        - kaiming_normal \n",
    "        - orthogonal\n",
    "        Biases are set to zero by default.\n",
    "        \"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                if init_type == 'xavier_uniform':\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    nn.init.zeros_(m.bias)\n",
    "                elif init_type == 'xavier_normal':\n",
    "                    nn.init.xavier_normal_(m.weight)\n",
    "                    nn.init.zeros_(m.bias)\n",
    "                elif init_type == 'kaiming_uniform':\n",
    "                    # For ReLU or similar activations\n",
    "                    nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "                    nn.init.zeros_(m.bias)\n",
    "                elif init_type == 'kaiming_normal':\n",
    "                    # For ReLU or similar activations\n",
    "                    nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                    nn.init.zeros_(m.bias)\n",
    "                elif init_type == 'orthogonal':\n",
    "                    nn.init.orthogonal_(m.weight)\n",
    "                    nn.init.zeros_(m.bias)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown init_type {init_type}\")\n",
    "                \n",
    "    def print_info(self):\n",
    "        encoder = \"\\n\"\n",
    "        out_encoder = \"\"\n",
    "        decoder = \"\\n\"\n",
    "        out_decoder = \"\"\n",
    "\n",
    "        for elmt in self.encoder.layers:\n",
    "            encoder += str(elmt) + \"\\n\"\n",
    "\n",
    "        for elmt in self.encoder.out_layers:\n",
    "            out_encoder += str(elmt) + \"\\n\"\n",
    "\n",
    "        for elmt in self.decoder.layers:\n",
    "            decoder += str(elmt) + \"\\n\"\n",
    "\n",
    "        for elmt in self.decoder.out_layers:\n",
    "            out_decoder += str(elmt) + \"\\n\"\n",
    "\n",
    "        print(f\"====================================================\\n\\\n",
    "Model: {self.__class__.__name__}\\n\\\n",
    "\\n\\tArchitecture encoder: {encoder}\\\n",
    "{out_encoder}\\n\\\n",
    "\\tArchitecture decoder: {decoder}\\\n",
    "{out_decoder} \\n\\\n",
    "Theta dim: {self.theta_dim}\\n\\\n",
    "y dim: {self.y_dim}\\n\\\n",
    "z dim: {self.z_dim}\\n\\\n",
    "====================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependent cVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dependent_cVAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Complete Conditional VAE:\n",
    "      - Encoder:   q(z | theta, y)\n",
    "      - Prior:     p(z | y)\n",
    "      - Decoder:   p(theta | z, y)\n",
    "\n",
    "    Parameters:\n",
    "      theta: parameter of interest (dimension theta_dim)\n",
    "      y: observation (dimension y_dim)\n",
    "      z: latent variable (dimension z_dim)\n",
    "    \"\"\"\n",
    "    def __init__(self, theta_dim, y_dim, z_dim,\n",
    "                 encoder_hidden_dim: list,\n",
    "                 prior_hidden_dim: list,\n",
    "                 decoder_hidden_dim: list,\n",
    "                 init_type='xavier_uniform'):\n",
    "        super(Dependent_cVAE, self).__init__()\n",
    "        self.encoder = Encoder(theta_dim, y_dim, z_dim, hidden_dim=encoder_hidden_dim)\n",
    "        self.prior = PriorNetwork(y_dim, z_dim, hidden_dim=prior_hidden_dim)\n",
    "        self.decoder = Decoder(z_dim, y_dim, theta_dim, hidden_dim=decoder_hidden_dim)\n",
    "        self._init_weights(init_type)\n",
    "\n",
    "        self.theta_dim = theta_dim\n",
    "        self.y_dim = y_dim\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, theta, y):\n",
    "        # Encoder: q(z | theta, y)\n",
    "        mu_q, log_var_q = self.encoder(theta, y)\n",
    "        # Prior: p(z | y)\n",
    "        mu_p, log_var_p = self.prior(y)\n",
    "        # Sample latent variable z ~ q(z | theta, y)\n",
    "        z = self.reparameterize(mu_q, log_var_q)\n",
    "        # Decoder: p(theta | z, y)\n",
    "        mu_theta, log_var_theta = self.decoder(z, y)\n",
    "        return theta, mu_q, log_var_q, mu_p, log_var_p, mu_theta, log_var_theta\n",
    "\n",
    "    def loss_function(self, theta, mu_q, log_var_q, mu_p, log_var_p, mu_theta, log_var_theta, beta):\n",
    "        # Convert log-variances to variances\n",
    "        var_q = torch.exp(log_var_q)\n",
    "        var_p = torch.exp(log_var_p)\n",
    "        var_theta = torch.exp(log_var_theta)\n",
    "\n",
    "        # KL divergence between q(z|theta,y)=N(mu_q,var_q) and p(z|y)=N(mu_p,var_p)\n",
    "        KL = beta * 0.5 * torch.mean(\n",
    "            (log_var_p - log_var_q) + (var_q + (mu_q - mu_p)**2) / var_p - 1\n",
    "        )\n",
    "        # Gaussian Negative Log-Likelihood for theta reconstruction (ignoring constants)\n",
    "        NLL = torch.mean(\n",
    "            log_var_theta + torch.pow(theta - mu_theta, 2) / (var_theta)\n",
    "        )\n",
    "        return KL, NLL, KL + NLL\n",
    "\n",
    "    def sample(self, num_samples, y):\n",
    "        # Set the model to evaluation mode\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            # Ensure y is a float tensor and repeat for num_samples\n",
    "            y = torch.as_tensor(y, dtype=torch.float32).repeat(num_samples, 1)\n",
    "            # Obtain latent parameters from the prior network\n",
    "            mu_p, log_var_p = self.prior(y)\n",
    "            # Reparameterize to sample z\n",
    "            z = self.reparameterize(mu_p, log_var_p)\n",
    "            # Decode to get theta reconstruction parameters\n",
    "            mu_theta, log_var_theta = self.decoder(z, y)\n",
    "            # Sample theta using the reparameterization trick\n",
    "            theta = self.reparameterize(mu_theta, log_var_theta)\n",
    "        return theta\n",
    "\n",
    "    def _init_weights(self, init_type):\n",
    "        \"\"\"\n",
    "        Initialize weights in the network with different methods:\n",
    "        - xavier_uniform\n",
    "        - xavier_normal\n",
    "        - kaiming_uniform (He)\n",
    "        - kaiming_normal\n",
    "        - orthogonal\n",
    "        Biases are set to zero by default.\n",
    "\n",
    "        Usage:\n",
    "        Call this inside your model's __init__ or a separate initialization method.\n",
    "            Example:\n",
    "            self._init_weights(init_type='xavier_uniform')\n",
    "        \"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                if init_type == 'xavier_uniform':\n",
    "                    nn.init.xavier_uniform_(m.weight)\n",
    "                    nn.init.zeros_(m.bias)\n",
    "                elif init_type == 'xavier_normal':\n",
    "                    nn.init.xavier_normal_(m.weight)\n",
    "                    nn.init.zeros_(m.bias)\n",
    "                elif init_type == 'kaiming_uniform':\n",
    "                    # For ReLU or similar activations\n",
    "                    nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "                    nn.init.zeros_(m.bias)\n",
    "                elif init_type == 'kaiming_normal':\n",
    "                    # For ReLU or similar activations\n",
    "                    nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                    nn.init.zeros_(m.bias)\n",
    "                elif init_type == 'orthogonal':\n",
    "                    nn.init.orthogonal_(m.weight)\n",
    "                    nn.init.zeros_(m.bias)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown init_type {init_type}\")\n",
    "\n",
    "    def print_info(self):\n",
    "            encoder = \"\\n\"\n",
    "            out_encoder = \"\"\n",
    "            prior = \"\\n\"\n",
    "            out_prior = \"\"\n",
    "            decoder = \"\\n\"\n",
    "            out_decoder = \"\"\n",
    "\n",
    "            for elmt in self.encoder.layers:\n",
    "                encoder += str(elmt) + \"\\n\"\n",
    "\n",
    "            for elmt in self.encoder.out_layers:\n",
    "                out_encoder += str(elmt) + \"\\n\"\n",
    "\n",
    "            for elmt in self.prior.layers:\n",
    "                prior += str(elmt) + \"\\n\"\n",
    "\n",
    "            for elmt in self.prior.out_layers:\n",
    "                out_prior += str(elmt) + \"\\n\"\n",
    "\n",
    "            for elmt in self.decoder.layers:\n",
    "                decoder += str(elmt) + \"\\n\"\n",
    "\n",
    "            for elmt in self.decoder.out_layers:\n",
    "                out_decoder += str(elmt) + \"\\n\"\n",
    "\n",
    "            print(f\"====================================================\\n\\\n",
    "Model: {self.__class__.__name__}\\n\\\n",
    "\\n\\tArchitecture Encoder: {encoder}\\\n",
    "{out_encoder}\\n\\\n",
    "\\tArchitecture Prior: {prior}\\\n",
    "{out_prior}\\n\\\n",
    "\\tArchitecture Decoder: {decoder}\\\n",
    "{out_decoder} \\n\\\n",
    "Theta dim: {self.theta_dim}\\n\\\n",
    "y dim: {self.y_dim}\\n\\\n",
    "z_dim: {self.z_dim}\\n\\\n",
    "====================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masked Autoregressive Flows (MAF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAF(nn.Module):\n",
    "    def __init__(self, theta_dim,\n",
    "                       y_dim,\n",
    "                       num_transforms, \n",
    "                       hidden_dim, \n",
    "                       num_blocks,\n",
    "                       transform = MaskedAffineAutoregressiveTransform, \n",
    "                       activation = F.elu,\n",
    "                       use_residual_blocks = True, \n",
    "                       random_mask = False,\n",
    "                       dropout_probability = 0.0,\n",
    "                       use_batch_norm = True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.theta_dim = theta_dim\n",
    "        self.y_dim = y_dim\n",
    "        self.num_transforms = num_transforms\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_blocks = num_blocks\n",
    "        self.transform = transform \n",
    "\n",
    "        #Defining base distribution\n",
    "        base_dist = StandardNormal(shape=[theta_dim])\n",
    "        self.base_dist = base_dist\n",
    "\n",
    "        \n",
    "\n",
    "        #Defining each transformation using the chosen spline\n",
    "        transforms = []\n",
    "        for _ in range(num_transforms):\n",
    "            transforms.append(transform(features=theta_dim,\n",
    "                                        hidden_features=hidden_dim,\n",
    "                                        context_features=y_dim,\n",
    "                                        num_blocks=num_blocks,\n",
    "                                        use_residual_blocks=use_residual_blocks,\n",
    "                                        random_mask=random_mask,\n",
    "                                        activation=activation,\n",
    "                                        dropout_probability=dropout_probability,\n",
    "                                        use_batch_norm=use_batch_norm))\n",
    "            #Activating permutation\n",
    "            perm = torch.randperm(theta_dim)\n",
    "            perm_transform = Permutation(perm)\n",
    "            transforms.append(perm_transform)\n",
    "\n",
    "\n",
    "        #Combine all transformations and define the model\n",
    "        transform = CompositeTransform(transforms)\n",
    "        self.flow = Flow(transform, base_dist)\n",
    "        \n",
    "     #Forward pass is calculating the loss function directly\n",
    "    def forward(self, theta, y):\n",
    "        return self.flow.log_prob(theta, context=y).mean()\n",
    "        \n",
    "    def sample(self, num_samples, y):\n",
    "        return self.flow.sample(num_samples, context=y)\n",
    "\n",
    "    def print_info(self):\n",
    "\n",
    "        print(f\"====================================================\\n\\\n",
    "\\tModel: {self.__class__.__name__}\\n\\\n",
    "\\n\\tTransformation: {self.transform}\\\n",
    "\\n\\tBase distribution: {self.base_dist}\\\n",
    "\\n\\tNumber of transformations: {self.num_transforms}\\\n",
    "\\n\\tNumber of residual blocks: {self.num_blocks}\\\n",
    "\\n\\tHidden features: {self.hidden_dim}\\\n",
    "\\n\\tTheta dim: {self.theta_dim}\\\n",
    "\\n\\ty dim: {self.y_dim}\\n\\\n",
    "====================================================\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Spline Flows (NSF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NSF(nn.Module):\n",
    "    def __init__(self, theta_dim,\n",
    "                       y_dim,\n",
    "                       num_transforms, \n",
    "                       hidden_dim, \n",
    "                       num_blocks,\n",
    "                       spline,\n",
    "                       tail_bound,\n",
    "                       tails = \"linear\", \n",
    "                       activation = F.elu, \n",
    "                       use_batch_norm = True):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        #Save input arguments for printing \n",
    "        self.theta_dim = theta_dim\n",
    "        self.y_dim = y_dim\n",
    "        self.num_transforms = num_transforms\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_blocks = num_blocks\n",
    "        self.spline = spline\n",
    "        self.tail_bound = tail_bound\n",
    "        self.tails = tails\n",
    "        self.activation = activation\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "\n",
    "        #Defining base distribution\n",
    "        base_dist = StandardNormal(shape=[theta_dim])\n",
    "        self.base_dist = base_dist\n",
    "\n",
    "        #Activating permutation\n",
    "        perm = torch.randperm(theta_dim)\n",
    "        perm_transform = Permutation(perm)\n",
    "\n",
    "        #Defining each transformation using the chosen spline\n",
    "        transforms = []\n",
    "        for i in range(num_transforms):\n",
    "\n",
    "            #mask for coupling\n",
    "            mask = torch.arange(theta_dim) % 2 == i % 2\n",
    "            mask = mask[torch.randperm(theta_dim)]\n",
    "\n",
    "            transforms.append(spline(mask,\n",
    "                                     self._create_resinet(\n",
    "                                     context_features=y_dim,\n",
    "                                     hidden_features=hidden_dim,\n",
    "                                     num_blocks=num_blocks,\n",
    "                                     use_batch_norm=use_batch_norm,\n",
    "                                     activation=activation), tail_bound=tail_bound,\n",
    "                                                             tails=tails))\n",
    "            \n",
    "            transforms.append(perm_transform)\n",
    "\n",
    "\n",
    "        #Combine all transformations and define the model\n",
    "        transform = CompositeTransform(transforms)\n",
    "        self.flow = Flow(transform, base_dist)\n",
    "\n",
    "\n",
    "\n",
    "    #Function for creating the residual net, controlling the parameters of the spline\n",
    "    def _create_resinet(self, context_features: int, \n",
    "                              hidden_features: int,\n",
    "                              num_blocks: int,\n",
    "                              use_batch_norm: bool,\n",
    "                              activation: Type):\n",
    "        def func(in_dim: int, out_dim: int):\n",
    "            return nets.ResidualNet(in_dim, \n",
    "                                    out_dim, \n",
    "                                    hidden_features=hidden_features,\n",
    "                                    context_features=context_features, \n",
    "                                    num_blocks=num_blocks, \n",
    "                                    activation=activation, \n",
    "                                    use_batch_norm=use_batch_norm)  \n",
    "        return func\n",
    "    \n",
    "    #Forward pass is calculating the loss function directly\n",
    "    def forward(self, theta, y):\n",
    "        return self.flow.log_prob(theta, context=y).mean()\n",
    "    \n",
    "    def loss(self, theta, y):\n",
    "        num_samples = theta.shape[0]\n",
    "        u = self.base_dist._sample(num_samples=num_samples, context=None)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def sample(self, num_samples, y):\n",
    "        return self.flow.sample(num_samples, context=y)\n",
    "\n",
    "    def print_info(self):\n",
    "\n",
    "        print(f\"====================================================\\n\\\n",
    "\\tModel: {self.__class__.__name__}\\n\\\n",
    "\\n\\tSpline: {self.spline}\\\n",
    "\\n\\tBase distribution: {self.base_dist}\\\n",
    "\\n\\tNumber of transformations: {self.num_transforms}\\\n",
    "\\n\\tNumber of residual blocks: {self.num_blocks}\\\n",
    "\\n\\tHidden features: {self.hidden_dim}\\\n",
    "\\n\\tTheta dim: {self.theta_dim}\\\n",
    "\\n\\ty dim: {self.y_dim}\\n\\\n",
    "====================================================\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for running a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, \n",
    "              num_samples: int,\n",
    "              task_name: str, \n",
    "              learning_rate: float,\n",
    "              batch_size: int,\n",
    "              epochs: int,\n",
    "              early_stopping_patience: int,\n",
    "              scaler = StandardScaler,\n",
    "              cvae_z_dim: int = 0,\n",
    "              cvae_beta: int = 0,\n",
    "              cvae_gradient_clipping_threshold: int = 10,\n",
    "              cvae_encoder_hidden_dim: list = [],\n",
    "              cvae_decoder_hidden_dim: list = [],\n",
    "              cvae_prior_hidden_dim: list = [],\n",
    "              cvae_init_weight_type: str = 'kaiming_normal',\n",
    "              nflows_NSF_spline: Type = None, \n",
    "              nflows_NSF_tail_bound: int = 0,\n",
    "              nflows_MAF_transform: Type = None,\n",
    "              nflows_MAF_use_residual_block: bool = True,\n",
    "              nflows_MAF_random_mask: bool = False,\n",
    "              nflows_MAF_dropout_probability: float = 0.0,\n",
    "              nflows_num_transforms: int = 0,\n",
    "              nflows_hidden_dim: int = 0,\n",
    "              nflows_num_blocks: int = 0,\n",
    "              nflows_use_batch_norm = True,\n",
    "              nflows_activation_func = F.elu,\n",
    "              save_model: bool = False,\n",
    "              save_fig: bool = False,\n",
    "              save_generated_dataset: bool = False,\n",
    "              seed: int = 0):\n",
    "    \n",
    "    \"\"\"\n",
    "    For a given generative model and model parameters, the function trains it on samples from a prior distribution\n",
    "    and a likelihood. The model should then be able to generate samples for the posterior distribution.\n",
    "    The samples are plotted against the true posterior distribution and such figure is displayed in the end.\n",
    "    \n",
    "    Args:\n",
    "        -- Shared Parameters -- \n",
    "        num_samples: Number of samples the model should be trained on.\n",
    "        task_name: The name of the benchmark model to approximate the posterior of. \n",
    "        learning_rate: The learning rate during training.\n",
    "        batch_size: Batch size for the training dataset\n",
    "        epochs: Number of epochs.\n",
    "        early_stopping_patience: Early stopping criteria.\n",
    "        scaler: Scaler for training/validation dataset. Default is StandardScaler\n",
    "\n",
    "        -- cVAE Parameters -- \n",
    "        cvae_z_dim: latent space dimension\n",
    "        cvae_beta: Beta factor for loss function\n",
    "        cvae_gradient_clipping_threshold: Threshold for gradient clipping. Default 10.\n",
    "        cvae_encoder_hidden_dim: List of encoder hidden dimensions and layers.\n",
    "        cvae_decoder_hidden_dim: List of decoder hidden dimensions and layers.\n",
    "        cvae_prior_hidden_dim: List of prior hidden dimensions and layers (If dependent cVAE)\n",
    "        cvae_init_weight_type: Weight initializer for more efficient training. Default \"kaiming_normal\"\n",
    "\n",
    "        -- Flow Based Methods Parameters -- \n",
    "        nflows_num_transforms: Number of transformations\n",
    "        nflows_hidden_dim: Hidden dimension of Residual networks\n",
    "        nflows_num_blocks: Number of Residual network blocks\n",
    "        nflows_spline: The spline to use from nflows.transforms\n",
    "        nflows_tail_bound: The tail bound for the spline.\n",
    "\n",
    "        -- Saving Model -- \n",
    "        save_model: 'True' to save the trained model.pth\n",
    "        save_fig: 'True' to save the figure of generated vs true posterior\n",
    "        save_generated_dataset: 'True' to save .npz dataset of generated posterior samples.\n",
    "        seed: The seed, default 0\n",
    "        \n",
    "    Returns:\n",
    "        The function trains and displays a figure of approximated posterior distribution and reference.\n",
    "        If all parameters for saving the model are true, the function saves the figure, dataset and model \n",
    "        and displays the figure as well. Otherwise, the figure is displayed and nothing is saved.\n",
    "    \"\"\"\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # ------------------------------\n",
    "    # Data Gathering & Preparation \n",
    "    # ------------------------------\n",
    "\n",
    "    #Script for generating training datasets\n",
    "    generate_dataset(task_name, num_samples, save_file=True)\n",
    "\n",
    "    #Finding the generated dataset\n",
    "    dataset_path = os.path.join( \n",
    "                                f\"datasets\", f\"{task_name}\", \n",
    "                                f\"training_data_{task_name}_budget_{int(num_samples/1000)}k.npz\")\n",
    "    dataset_npz = np.load(dataset_path)\n",
    "\n",
    "    #Separating distribution parameters (thetas) and observations (ys)\n",
    "    thetas = dataset_npz['thetas'] # shape: (num_train_samples, theta_dim)\n",
    "    ys = dataset_npz['y_samples']  # shape: (num_train_samples, y_dim)\n",
    "\n",
    "    theta_dim = thetas.shape[1]\n",
    "    y_dim = ys.shape[1]\n",
    "\n",
    "    # ------------------------------\n",
    "    # Data Scaling (StandardScaler default)\n",
    "    # ------------------------------\n",
    "\n",
    "    # seperate scalers for theta and y\n",
    "    theta_scaler = scaler()\n",
    "    y_scaler = scaler()\n",
    "\n",
    "    thetas_scaled = theta_scaler.fit_transform(thetas)\n",
    "    ys_scaled = y_scaler.fit_transform(ys)\n",
    "\n",
    "    # ------------------------------\n",
    "    # Splitting dataset & loading into dataloader\n",
    "    # ------------------------------\n",
    "\n",
    "    thetas_tensor = torch.tensor(thetas_scaled, dtype=torch.float32)\n",
    "    ys_tensor = torch.tensor(ys_scaled, dtype=torch.float32)\n",
    "\n",
    "    dataset = TensorDataset(thetas_tensor, ys_tensor)\n",
    "    train_size = int(0.9 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # ------------------------------\n",
    "    # Device and Model Initialization\n",
    "    # ------------------------------\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    if model == Dependent_cVAE:\n",
    "        model = Dependent_cVAE(theta_dim=theta_dim, y_dim=y_dim, z_dim=cvae_z_dim,\n",
    "                               encoder_hidden_dim=cvae_encoder_hidden_dim, \n",
    "                               prior_hidden_dim=cvae_prior_hidden_dim, \n",
    "                               decoder_hidden_dim=cvae_decoder_hidden_dim, \n",
    "                               init_type=cvae_init_weight_type).to(device)\n",
    "    \n",
    "        \n",
    "    elif model == Independent_cVAE:\n",
    "        model = Independent_cVAE(theta_dim=theta_dim, y_dim=y_dim, z_dim=cvae_z_dim,\n",
    "                                 encoder_hidden_dim=cvae_encoder_hidden_dim, \n",
    "                                 decoder_hidden_dim=cvae_decoder_hidden_dim, \n",
    "                                 init_type=cvae_init_weight_type).to(device)\n",
    "          \n",
    "    elif model == NSF:\n",
    "        model = NSF(theta_dim=theta_dim, y_dim=y_dim, \n",
    "                    num_transforms=nflows_num_transforms, \n",
    "                    hidden_dim=nflows_hidden_dim, \n",
    "                    num_blocks=nflows_num_blocks,\n",
    "                    spline=nflows_NSF_spline, \n",
    "                    tail_bound=nflows_NSF_tail_bound,\n",
    "                    activation=nflows_activation_func,\n",
    "                    use_batch_norm=nflows_use_batch_norm,\n",
    "                    tails=\"linear\"\n",
    "                    ).to(device)\n",
    "        \n",
    "    elif model == MAF:\n",
    "        model = MAF(theta_dim=theta_dim,\n",
    "                    y_dim=y_dim,\n",
    "                    num_transforms=nflows_num_transforms, \n",
    "                    hidden_dim=nflows_hidden_dim, \n",
    "                    num_blocks=nflows_num_blocks,\n",
    "                    transform=nflows_MAF_transform,\n",
    "                    activation=nflows_activation_func,\n",
    "                    use_residual_blocks=nflows_MAF_use_residual_block,\n",
    "                    random_mask=nflows_MAF_random_mask,\n",
    "                    dropout_probability=nflows_MAF_dropout_probability,\n",
    "                    use_batch_norm = nflows_use_batch_norm)\n",
    "    else:\n",
    "        print(f\"The model: {model} is not defined.\")\n",
    "\n",
    "    \n",
    "    model.print_info()\n",
    "    model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience = 0\n",
    "\n",
    "    # ------------------------------\n",
    "    # Training Loop with Early Stopping\n",
    "    # ------------------------------\n",
    "    for epoch in range(epochs):\n",
    "            model.train()\n",
    "            train_loss_total = 0.0\n",
    "            train_KL_total = 0.0\n",
    "            train_NLL_total = 0.0\n",
    "            num_batches = 0\n",
    "            for theta_batch, y_batch in train_loader:\n",
    "                theta_batch, y_batch = theta_batch.to(device), y_batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if model.__class__.__name__ not in [\"NSF\", \"MAF\"]:\n",
    "                    outputs = model(theta_batch, y_batch)\n",
    "                    outputs = (*outputs, cvae_beta)\n",
    "                    KL, NLL, loss = model.loss_function(*outputs)\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=cvae_gradient_clipping_threshold)\n",
    "                    optimizer.step()\n",
    "                    train_loss_total += loss.item()\n",
    "                    train_KL_total += KL.item()\n",
    "                    train_NLL_total += NLL.item()\n",
    "\n",
    "                else:\n",
    "                    loss = -model.forward(theta_batch, y_batch)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    train_loss_total += loss.item()\n",
    "                \n",
    "                num_batches += 1\n",
    "            avg_train_loss = train_loss_total / num_batches\n",
    "            avg_train_KL = train_KL_total / num_batches\n",
    "            avg_train_NLL = train_NLL_total / num_batches\n",
    "\n",
    "            model.eval()\n",
    "            val_loss_total = 0.0\n",
    "            val_KL_total = 0.0\n",
    "            val_NLL_total = 0.0\n",
    "            num_val_batches = 0\n",
    "            with torch.no_grad():\n",
    "                for theta_batch, y_batch in val_loader:\n",
    "                    theta_batch, y_batch = theta_batch.to(device), y_batch.to(device)\n",
    "\n",
    "                    if model.__class__.__name__ not in [\"NSF\", \"MAF\"]:\n",
    "                        outputs = model(theta_batch, y_batch)\n",
    "                        outputs = (*outputs, cvae_beta)\n",
    "                        KL_val, NLL_val, loss_val = model.loss_function(*outputs)\n",
    "                        val_loss_total += loss_val.item()\n",
    "                        val_KL_total += KL_val.item()\n",
    "                        val_NLL_total += NLL_val.item()\n",
    "\n",
    "                    else:\n",
    "                        loss_val = -model.forward(theta_batch, y_batch)\n",
    "                        val_loss_total += loss_val.item()\n",
    "                    \n",
    "                    num_val_batches += 1\n",
    "            avg_val_loss = val_loss_total / num_val_batches\n",
    "            avg_val_KL = val_KL_total / num_val_batches\n",
    "            avg_val_NLL = val_NLL_total / num_val_batches\n",
    "\n",
    "            if model.__class__.__name__ not in [\"NSF\", \"MAF\"]:\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}] - \"\n",
    "                      f\"Train Loss: {avg_train_loss:.4f} (KL: {avg_train_KL:.4f}, NLL: {avg_train_NLL:.4f}) | \"\n",
    "                      f\"Val Loss: {avg_val_loss:.4f} (KL: {avg_val_KL:.4f}, NLL: {avg_val_NLL:.4f})\")\n",
    "            \n",
    "            else:\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}] - \"\n",
    "                      f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                patience = 0\n",
    "                torch.save(model.state_dict(), f\"{model.__class__.__name__}_{task_name}.pth\")\n",
    "            else:\n",
    "                patience += 1\n",
    "                if patience >= early_stopping_patience:\n",
    "                    print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                    break\n",
    "\n",
    "    model.load_state_dict(torch.load(f\"{model.__class__.__name__}_{task_name}.pth\", weights_only=True))\n",
    "    if not save_model:\n",
    "        os.remove(f\"{model.__class__.__name__}_{task_name}.pth\")\n",
    "\n",
    "  \n",
    "    # ------------------------------\n",
    "    #Plotting & saving dataset\n",
    "    # ------------------------------\n",
    "\n",
    "    # Scale the observation using the same y_scaler \n",
    "    task = sbibm.get_task(task_name)\n",
    "\n",
    "    \n",
    "    if task_name not in [\"sir\", \"lotka_volterra\"]:\n",
    "        # Get one observation (y) from the task\n",
    "        observation = task.get_observation(num_observation=1)\n",
    "\n",
    "    #Generating an observation (y) from bayesflow library, if the task is 'sir' or 'lotka volterra' \n",
    "    else:\n",
    "        if task_name == \"sir\":\n",
    "            #The true parameters for 'observation 1', sir, used in the SBIBM library \n",
    "            true_beta = 0.61479264\t\n",
    "            true_gamma = 0.19172086\n",
    "            true_theta = np.array([true_beta, true_gamma])\n",
    "            observation = SIR.simulator(true_theta)\n",
    "            observation = np.reshape(observation, (1, -1))\n",
    "\n",
    "        else:\n",
    "            #The true parameters for 'observation 1', Lotka volterra, used in the SBIBM library\n",
    "            true_alpha, true_beta = 0.6859157, 0.10761319\n",
    "            true_gamma, true_delta = 0.88789904, 0.116794825\n",
    "            true_theta = np.array([true_alpha, true_beta, true_gamma, true_delta])\n",
    "            observation = lotka_volterra.simulator(true_theta)\n",
    "            observation = np.reshape(observation, (1, -1))\n",
    "\n",
    "\n",
    "\n",
    "    #Get the reference samples for the observation (true posterior)\n",
    "    reference_samples = task.get_reference_posterior_samples(num_observation=1)\n",
    "\n",
    "    print(\"Original Observation:\", observation)\n",
    "\n",
    "    #Scale observation and make it a torch tensor\n",
    "    obs_scaled = y_scaler.transform(observation)\n",
    "    obs_scaled_tensor = torch.tensor(obs_scaled, dtype=torch.float32).to(device)\n",
    "\n",
    "    #Sample the thetas\n",
    "    if model.__class__.__name__ not in [\"NSF\", \"MAF\"]:\n",
    "        theta_samples_scaled = model.sample(10000, obs_scaled_tensor)\n",
    "    else:\n",
    "        theta_samples_scaled = model.sample(10000, obs_scaled_tensor)[0]\n",
    "\n",
    "    # Inverse-transform to the original scale\n",
    "    theta_samples = theta_scaler.inverse_transform(theta_samples_scaled.detach().cpu().numpy())\n",
    "\n",
    "    # Dynamically adjust the figure size based on the number of dimensions\n",
    "    max_columns = 5  # Maximum number of columns per row\n",
    "    num_rows = int(np.ceil(theta_dim / max_columns))  # Calculate the number of rows needed\n",
    "    fig_width = 15  \n",
    "    fig_height = num_rows * 3  # Height proportional to the number of rows\n",
    "\n",
    "    plt.figure(1, figsize=(fig_width, fig_height))  \n",
    "    # Create subplots\n",
    "    for i in range(theta_dim):\n",
    "        plt.subplot(num_rows, max_columns, i + 1)\n",
    "        if task_name != 'lotka_volterra':\n",
    "            sns.kdeplot(theta_samples[:, i], label=\"Generated Posterior\", fill=True, color='blue')\n",
    "            sns.kdeplot(reference_samples[:, i], label=\"True Posterior\", fill=True, color='red')\n",
    "\n",
    "            # Only keep the y-axis label for the first subplot\n",
    "            if i == 0:\n",
    "                plt.ylabel(\"Density\", fontsize=12)  # Add y-axis label for the first subplot\n",
    "            else:\n",
    "                plt.ylabel(\"\")  # Remove y-axis label for other subplots\n",
    "\n",
    "        else:\n",
    "            plt.hist(theta_samples[:, i], label=\"Generated Posterior\", color='blue', bins=100, density=True, alpha=0.7)\n",
    "            plt.hist(reference_samples[:, i], label=\"True Posterior\", color='red', bins=100, density=True, alpha=0.7)\n",
    "\n",
    "            # Only keep the y-axis label for the first subplot\n",
    "            if i == 0:\n",
    "                plt.ylabel(\"Frequency\", fontsize=12)  # Add y-axis label for the first subplot\n",
    "            else:\n",
    "                plt.ylabel(\"\")  # Remove y-axis label for other subplots\n",
    "        \n",
    "        \n",
    "        plt.xlabel(rf\"$\\theta_{{{i+1}}}$\", fontsize=12)  # Use LaTeX formatting for labels\n",
    "\n",
    "    #Dynamically adjusting legend\n",
    "    if theta_dim >= 5:\n",
    "        legend_x_axis = 0.5\n",
    "        legend_y_axis = 1\n",
    "        legend_size = 12\n",
    "    else:\n",
    "        legend_x_axis = theta_dim/10\n",
    "        legend_y_axis = 1\n",
    "        legend_size = 8\n",
    "\n",
    "    \n",
    "    # Add a single legend outside the subplots\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    fig = plt.gcf()\n",
    "\n",
    "    fig.legend(handles, labels, loc='upper center', \n",
    "               bbox_to_anchor=(legend_x_axis, legend_y_axis), \n",
    "               ncol=2, fontsize=legend_size)  \n",
    "\n",
    "    # Adjust layout for better spacing\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.9])  # Leave space for the legend at the top\n",
    "\n",
    "    \n",
    "    \n",
    "    # If two moons task - provide a 2d scatterplot, as well.\n",
    "    if task_name == 'two_moons':\n",
    "        plt.figure(2, figsize=(6, 6))\n",
    "        plt.scatter(theta_samples[:,0], theta_samples[:,1], s=0.01, alpha=0.7, c='blue', label='Generated Posterior')\n",
    "        plt.scatter(reference_samples[:,0], reference_samples[:,1], s=0.01, alpha=0.7, c='red', label='True Posterior')\n",
    "        plt.xlabel(rf\"$\\theta_{{{1}}}$\", fontsize=12)\n",
    "        plt.ylabel(rf\"$\\theta_{{{2}}}$\", fontsize=12)\n",
    " \n",
    "        custom_legend = [\n",
    "        Line2D([0], [0], marker='o', color='blue', markersize=10, \n",
    "               linestyle='None', alpha=1, label='Generated Posterior'),\n",
    "        Line2D([0], [0], marker='o', color='red', markersize=10, \n",
    "               linestyle='None', alpha=1, label='True Posterior')]\n",
    "    \n",
    "        # Add legend\n",
    "        fig = plt.gcf()\n",
    "        fig.legend(handles=custom_legend, \n",
    "                loc='upper center', \n",
    "                bbox_to_anchor=(0.5, 0.95),\n",
    "                ncol=2, \n",
    "                fontsize=8,\n",
    "                frameon=True) \n",
    "\n",
    "        # Adjust layout for better spacing\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.9])  # Leave space for the legend at the top\n",
    "\n",
    "\n",
    "\n",
    "    name_acro_mapping = {\n",
    "        \"Independent_cVAE\": \"indep\",\n",
    "        \"Dependent_cVAE\": \"dep\",\n",
    "        \"NSF\": \"NSF\",\n",
    "        \"MAF\": \"MAF\"\n",
    "        }\n",
    "    \n",
    "    acro = name_acro_mapping[model.__class__.__name__]\n",
    "\n",
    "    model_folder_path = os.path.join(os.getcwd(),\n",
    "                                    \"Flow Based Methods\" if acro in [\"NSF\", \"MAF\"] else \"cVAE\")\n",
    "    \n",
    "    model_figures_folder_path = os.path.join(model_folder_path,\n",
    "                                             f\"Figures - {model.__class__.__name__}\")\n",
    "    \n",
    "    # task_figures_folder_path = os.path.join(model_figures_folder_path, \n",
    "    #                                         task_name)\n",
    "\n",
    "    model_runs_folder_path = os.path.join(os.getcwd(),\n",
    "                                          \"Flow Based Methods\" if acro in [\"NSF\", \"MAF\"] else \"cVAE\", \n",
    "                                          f\"Runs - {model.__class__.__name__}\")\n",
    "    \n",
    "    task_runs_folder_path = os.path.join(model_runs_folder_path, \n",
    "                                         task_name)\n",
    "\n",
    "    \n",
    "\n",
    "    figure_path = os.path.join(model_figures_folder_path,\n",
    "                               f\"fig_{acro}_{task_name}_budget_{int(num_samples/1000)}k.pdf\")\n",
    "    \n",
    "    dataset_path = os.path.join(task_runs_folder_path, \n",
    "                                f\"dataset_1_{acro}_{task_name}_budget_{int(num_samples/1000)}k.npz\")\n",
    "    \n",
    "    if task_name == 'two_moons':\n",
    "        plot_path = os.path.join(model_figures_folder_path, \n",
    "                                 f\"plot_{acro}_{task_name}_budget_{int(num_samples/1000)}k.pdf\")\n",
    "    \n",
    "    if save_fig:\n",
    "        if not os.path.exists(model_folder_path):\n",
    "            os.mkdir(model_folder_path)\n",
    "        if not os.path.exists(model_figures_folder_path):\n",
    "            os.mkdir(model_figures_folder_path)\n",
    "        # if not os.path.exists(task_figures_folder_path):\n",
    "        #     os.mkdir(task_figures_folder_path)\n",
    "        if not os.path.exists(figure_path):\n",
    "            plt.figure(1)\n",
    "            plt.savefig(figure_path)\n",
    "      \n",
    "            print(f\"The figure has been saved at: \\n{figure_path}\")\n",
    "            if task_name == \"two_moons\":\n",
    "                plt.figure(2)\n",
    "                plt.savefig(plot_path)\n",
    "                plt.show()  \n",
    "    \n",
    "        else:\n",
    "            print(f\"A figure for this model, task and budget already exists. Replacing it\")\n",
    "            plt.figure(1)\n",
    "            plt.savefig(figure_path)\n",
    "         \n",
    "            if task_name == \"two_moons\":\n",
    "                plt.figure(2)\n",
    "                plt.savefig(plot_path)  \n",
    "                plt.show() \n",
    "           \n",
    "        plt.figure(1)\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.figure(1)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    if save_generated_dataset:\n",
    "        index = 1\n",
    "        if not os.path.exists(model_runs_folder_path):\n",
    "            os.mkdir(model_runs_folder_path)\n",
    "        if not os.path.exists(task_runs_folder_path):\n",
    "            os.mkdir(task_runs_folder_path)\n",
    "        if not os.path.exists(dataset_path):\n",
    "            np.savez(dataset_path, thetas=theta_samples)\n",
    "        else:\n",
    "            #Add index to generated dataset, if previous datasets already exists. \n",
    "            while os.path.exists(dataset_path):\n",
    "                index += 1\n",
    "                dataset_path = os.path.join(task_runs_folder_path, \n",
    "                                            f\"dataset_{index}_{acro}_{task_name}_budget_{int(num_samples/1000)}k.npz\")\n",
    "                \n",
    "            dataset_path = os.path.join(task_runs_folder_path, \n",
    "                                            f\"dataset_{index}_{acro}_{task_name}_budget_{int(num_samples/1000)}k.npz\")\n",
    "\n",
    "            np.savez(dataset_path, thetas=theta_samples)\n",
    "            print(f\"The generated dataset has been saved at:\\n {dataset_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dep = [{\n",
    "    \"model\": Dependent_cVAE,\n",
    "    \"task_name\": \"gaussian_linear\",\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"batch_size\": 16,\n",
    "    \"epochs\": 50,\n",
    "    \"early_stopping_patience\": 20,\n",
    "    \"scaler\": StandardScaler,\n",
    "    \"cvae_z_dim\": 10,\n",
    "    \"cvae_beta\": 1,\n",
    "    \"cvae_gradient_clipping_threshold\": 10,\n",
    "    \"cvae_encoder_hidden_dim\": [128,128,128],\n",
    "    \"cvae_decoder_hidden_dim\": [128,128],\n",
    "    \"cvae_prior_hidden_dim\": [64,64]\n",
    "},\n",
    "{\n",
    "    \"model\": Dependent_cVAE,\n",
    "    \"task_name\": \"gaussian_linear_uniform\",\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 50,\n",
    "    \"early_stopping_patience\": 20,\n",
    "    \"scaler\": StandardScaler,\n",
    "    \"cvae_z_dim\": 10,\n",
    "    \"cvae_beta\": 1,\n",
    "    \"cvae_gradient_clipping_threshold\": 10,\n",
    "    \"cvae_encoder_hidden_dim\": [128,128,128],\n",
    "    \"cvae_decoder_hidden_dim\": [128,128],\n",
    "    \"cvae_prior_hidden_dim\": [256,256]\n",
    "},\n",
    "{\n",
    "    \"model\": Dependent_cVAE,\n",
    "    \"task_name\": \"slcp\",\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"batch_size\": 16,\n",
    "    \"epochs\": 50,\n",
    "    \"early_stopping_patience\": 20,\n",
    "    \"scaler\": StandardScaler,\n",
    "    \"cvae_z_dim\": 5,\n",
    "    \"cvae_beta\": 1,\n",
    "    \"cvae_gradient_clipping_threshold\": 10,\n",
    "    \"cvae_encoder_hidden_dim\": [128,128,128],\n",
    "    \"cvae_decoder_hidden_dim\": [128,128],\n",
    "    \"cvae_prior_hidden_dim\": [128,128]\n",
    "},\n",
    "{\n",
    "    \"model\": Dependent_cVAE,\n",
    "    \"task_name\": \"slcp_distractors\",\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"batch_size\": 16,\n",
    "    \"epochs\": 50,\n",
    "    \"early_stopping_patience\": 20,\n",
    "    \"scaler\": StandardScaler,\n",
    "    \"cvae_z_dim\": 8,\n",
    "    \"cvae_beta\": 1,\n",
    "    \"cvae_gradient_clipping_threshold\": 10,\n",
    "    \"cvae_encoder_hidden_dim\": [256,256,256],\n",
    "    \"cvae_decoder_hidden_dim\": [256,256],\n",
    "    \"cvae_prior_hidden_dim\": [128,128]\n",
    "},\n",
    "{\n",
    "    \"model\": Dependent_cVAE,\n",
    "    \"task_name\": \"bernoulli_glm\",\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 50,\n",
    "    \"early_stopping_patience\": 20,\n",
    "    \"scaler\": StandardScaler,\n",
    "    \"cvae_z_dim\": 10,\n",
    "    \"cvae_beta\": 1,\n",
    "    \"cvae_gradient_clipping_threshold\": 10,\n",
    "    \"cvae_encoder_hidden_dim\": [256,256,256],\n",
    "    \"cvae_decoder_hidden_dim\": [256,256,256],\n",
    "    \"cvae_prior_hidden_dim\": [64,64,64]\n",
    "},\n",
    "{\n",
    "    \"model\": Dependent_cVAE,\n",
    "    \"task_name\": \"bernoulli_glm_raw\",\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 50,\n",
    "    \"early_stopping_patience\": 20,\n",
    "    \"scaler\": StandardScaler,\n",
    "    \"cvae_z_dim\": 10,\n",
    "    \"cvae_beta\": 10,\n",
    "    \"cvae_gradient_clipping_threshold\": 10,\n",
    "    \"cvae_encoder_hidden_dim\": [256,256,256,256],\n",
    "    \"cvae_decoder_hidden_dim\": [256,256,256],\n",
    "    \"cvae_prior_hidden_dim\": [128,128,128]\n",
    "},\n",
    "{\n",
    "    \"model\": Dependent_cVAE,\n",
    "    \"task_name\": \"gaussian_mixture\",\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"batch_size\": 16,\n",
    "    \"epochs\": 50,\n",
    "    \"early_stopping_patience\": 20,\n",
    "    \"scaler\": StandardScaler,\n",
    "    \"cvae_z_dim\": 4,\n",
    "    \"cvae_beta\": 1,\n",
    "    \"cvae_gradient_clipping_threshold\": 10,\n",
    "    \"cvae_encoder_hidden_dim\": [128,128,128],\n",
    "    \"cvae_decoder_hidden_dim\": [128,128],\n",
    "    \"cvae_prior_hidden_dim\": [32]\n",
    "},\n",
    "{\n",
    "    \"model\": Dependent_cVAE,\n",
    "    \"task_name\": \"two_moons\",\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 50,\n",
    "    \"early_stopping_patience\": 20,\n",
    "    \"scaler\": StandardScaler,\n",
    "    \"cvae_z_dim\": 2,\n",
    "    \"cvae_beta\": 1,\n",
    "    \"cvae_gradient_clipping_threshold\": 10,\n",
    "    \"cvae_encoder_hidden_dim\": [128,128,128],\n",
    "    \"cvae_decoder_hidden_dim\": [128,128],\n",
    "    \"cvae_prior_hidden_dim\": [128,128]\n",
    "},\n",
    "{\n",
    "    \"model\": Dependent_cVAE,\n",
    "    \"task_name\": \"sir\",\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 50,\n",
    "    \"early_stopping_patience\": 20,\n",
    "    \"scaler\": StandardScaler,\n",
    "    \"cvae_z_dim\": 2,\n",
    "    \"cvae_beta\": 1,\n",
    "    \"cvae_gradient_clipping_threshold\": 10,\n",
    "    \"cvae_encoder_hidden_dim\": [128,128,128,128],\n",
    "    \"cvae_decoder_hidden_dim\": [128,128,128,128],\n",
    "    \"cvae_prior_hidden_dim\": [256,256,256]\n",
    "},\n",
    "{\n",
    "    \"model\": Dependent_cVAE,\n",
    "    \"task_name\": \"lotka_volterra\",\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"batch_size\": 256,\n",
    "    \"epochs\": 50,\n",
    "    \"early_stopping_patience\": 20,\n",
    "    \"scaler\": StandardScaler,\n",
    "    \"cvae_z_dim\": 8,\n",
    "    \"cvae_beta\": 10,\n",
    "    \"cvae_gradient_clipping_threshold\": 10,\n",
    "    \"cvae_encoder_hidden_dim\": [128,128,128],\n",
    "    \"cvae_decoder_hidden_dim\": [128,128,128],\n",
    "    \"cvae_prior_hidden_dim\": [64,64]\n",
    "}\n",
    "]\n",
    "\n",
    "models_indep = [{\n",
    "    \"model\": Independent_cVAE,\n",
    "    \"task_name\": \"gaussian_linear\",\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"batch_size\": 16,\n",
    "    \"epochs\": 50,\n",
    "    \"early_stopping_patience\": 20,\n",
    "    \"scaler\": StandardScaler,\n",
    "    \"cvae_z_dim\": 10,\n",
    "    \"cvae_beta\": 1,\n",
    "    \"cvae_gradient_clipping_threshold\": 10,\n",
    "    \"cvae_encoder_hidden_dim\": [128,128,128],\n",
    "    \"cvae_decoder_hidden_dim\": [128,128,128]\n",
    "},\n",
    "{\n",
    "    \"model\": Independent_cVAE,\n",
    "    \"task_name\": \"gaussian_linear_uniform\",\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 50,\n",
    "    \"early_stopping_patience\": 20,\n",
    "    \"scaler\": StandardScaler,\n",
    "    \"cvae_z_dim\": 10,\n",
    "    \"cvae_beta\": 10,\n",
    "    \"cvae_gradient_clipping_threshold\": 10,\n",
    "    \"cvae_encoder_hidden_dim\": [128,128,128,128],\n",
    "    \"cvae_decoder_hidden_dim\": [128,128,128]\n",
    "},\n",
    "{\n",
    "    \"model\": Independent_cVAE,\n",
    "    \"task_name\": \"slcp\",\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"batch_size\": 16,\n",
    "    \"epochs\": 50,\n",
    "    \"early_stopping_patience\": 20,\n",
    "    \"scaler\": StandardScaler,\n",
    "    \"cvae_z_dim\": 5,\n",
    "    \"cvae_beta\": 1,\n",
    "    \"cvae_gradient_clipping_threshold\": 10,\n",
    "    \"cvae_encoder_hidden_dim\": [512,512,512],\n",
    "    \"cvae_decoder_hidden_dim\": [512,512,512]\n",
    "},\n",
    "{\n",
    "    \"model\": Independent_cVAE,\n",
    "    \"task_name\": \"slcp_distractors\",\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"batch_size\": 16,\n",
    "    \"epochs\": 50,\n",
    "    \"early_stopping_patience\": 20,\n",
    "    \"scaler\": StandardScaler,\n",
    "    \"cvae_z_dim\": 5,\n",
    "    \"cvae_beta\": 1,\n",
    "    \"cvae_gradient_clipping_threshold\": 10,\n",
    "    \"cvae_encoder_hidden_dim\": [512,512,512,512],\n",
    "    \"cvae_decoder_hidden_dim\": [512,512,512]\n",
    "},\n",
    "{\n",
    "    \"model\": Independent_cVAE,\n",
    "    \"task_name\": \"bernoulli_glm\",\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"batch_size\": 16,\n",
    "    \"epochs\": 50,\n",
    "    \"early_stopping_patience\": 20,\n",
    "    \"scaler\": StandardScaler,\n",
    "    \"cvae_z_dim\": 10,\n",
    "    \"cvae_beta\": 1,\n",
    "    \"cvae_gradient_clipping_threshold\": 10,\n",
    "    \"cvae_encoder_hidden_dim\": [256,256,256,256],\n",
    "    \"cvae_decoder_hidden_dim\": [256,256,256,256]\n",
    "},\n",
    "{\n",
    "    \"model\": Independent_cVAE,\n",
    "    \"task_name\": \"bernoulli_glm_raw\",\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"batch_size\": 16,\n",
    "    \"epochs\": 50,\n",
    "    \"early_stopping_patience\": 20,\n",
    "    \"scaler\": StandardScaler,\n",
    "    \"cvae_z_dim\": 5,\n",
    "    \"cvae_beta\": 0.1,\n",
    "    \"cvae_gradient_clipping_threshold\": 10,\n",
    "    \"cvae_encoder_hidden_dim\": [256,256,256,256],\n",
    "    \"cvae_decoder_hidden_dim\": [256,256,256,256]\n",
    "},\n",
    "{\n",
    "    \"model\": Independent_cVAE,\n",
    "    \"task_name\": \"gaussian_mixture\",\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"batch_size\": 16,\n",
    "    \"epochs\": 50,\n",
    "    \"early_stopping_patience\": 20,\n",
    "    \"scaler\": StandardScaler,\n",
    "    \"cvae_z_dim\": 2,\n",
    "    \"cvae_beta\": 1,\n",
    "    \"cvae_gradient_clipping_threshold\": 10,\n",
    "    \"cvae_encoder_hidden_dim\": [128,128,128],\n",
    "    \"cvae_decoder_hidden_dim\": [128,128]\n",
    "},\n",
    "{\n",
    "    \"model\": Independent_cVAE,\n",
    "    \"task_name\": \"two_moons\",\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"batch_size\": 16,\n",
    "    \"epochs\": 50,\n",
    "    \"early_stopping_patience\": 20,\n",
    "    \"scaler\": StandardScaler,\n",
    "    \"cvae_z_dim\": 2,\n",
    "    \"cvae_beta\": 1,\n",
    "    \"cvae_gradient_clipping_threshold\": 10,\n",
    "    \"cvae_encoder_hidden_dim\": [128,128,128],\n",
    "    \"cvae_decoder_hidden_dim\": [128,128]\n",
    "},\n",
    "{\n",
    "    \"model\": Independent_cVAE,\n",
    "    \"task_name\": \"sir\",\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 50,\n",
    "    \"early_stopping_patience\": 20,\n",
    "    \"scaler\": StandardScaler,\n",
    "    \"cvae_z_dim\": 2,\n",
    "    \"cvae_beta\": 1,\n",
    "    \"cvae_gradient_clipping_threshold\": 10,\n",
    "    \"cvae_encoder_hidden_dim\": [128,128,128,128],\n",
    "    \"cvae_decoder_hidden_dim\": [128,128]\n",
    "},\n",
    "{\n",
    "    \"model\": Independent_cVAE,\n",
    "    \"task_name\": \"lotka_volterra\",\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"batch_size\": 128,\n",
    "    \"epochs\": 50,\n",
    "    \"early_stopping_patience\": 20,\n",
    "    \"scaler\": StandardScaler,\n",
    "    \"cvae_z_dim\": 8,\n",
    "    \"cvae_beta\": 1,\n",
    "    \"cvae_gradient_clipping_threshold\": 10,\n",
    "    \"cvae_encoder_hidden_dim\": [256,256,256,256],\n",
    "    \"cvae_decoder_hidden_dim\": [256,256,256]\n",
    "}\n",
    "]\n",
    "\n",
    "models_NSF = [\n",
    "     {\n",
    "        \"model\": NSF,\n",
    "        \"task_name\": \"slcp\",\n",
    "        \"num_samples\": 5000,\n",
    "        \"nflows_NSF_spline\": PiecewiseRationalQuadraticCouplingTransform,\n",
    "        \"nflows_num_transforms\": 4,\n",
    "        \"nflows_hidden_dim\": 32,  #\n",
    "        \"nflows_num_blocks\": 4,\n",
    "        \"early_stopping_patience\": 20,\n",
    "        \"epochs\": 50,\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"batch_size\": 512,\n",
    "        \"scaler\": StandardScaler,\n",
    "        \"nflows_activation_func\": F.elu,\n",
    "        \"nflows_use_batch_norm\": True,\n",
    "        \"nflows_NSF_tail_bound\": 3\n",
    "    },\n",
    "    {\n",
    "        \"model\": NSF,\n",
    "        \"task_name\": \"gaussian_linear_uniform\",\n",
    "        \"num_samples\": 5000,\n",
    "        \"nflows_NSF_spline\": PiecewiseRationalQuadraticCouplingTransform,\n",
    "        \"nflows_num_transforms\": 4,\n",
    "        \"nflows_hidden_dim\": 256,\n",
    "        \"nflows_num_blocks\": 3,\n",
    "        \"early_stopping_patience\": 20,\n",
    "        \"epochs\": 50,\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"batch_size\": 128,\n",
    "        \"scaler\": StandardScaler,\n",
    "        \"nflows_activation_func\": F.elu,\n",
    "        \"nflows_use_batch_norm\": True,\n",
    "        \"nflows_NSF_tail_bound\": 3\n",
    "    },\n",
    "    {\n",
    "        \"model\": NSF,\n",
    "        \"task_name\": \"gaussian_linear\",\n",
    "        \"num_samples\": 5000,\n",
    "        \"nflows_NSF_spline\": PiecewiseRationalQuadraticCouplingTransform,\n",
    "        \"nflows_num_transforms\": 3,#2\n",
    "        \"nflows_hidden_dim\": 64,#32\n",
    "        \"nflows_num_blocks\": 2,\n",
    "        \"early_stopping_patience\": 20,\n",
    "        \"epochs\": 50,\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"batch_size\": 128,\n",
    "        \"scaler\": StandardScaler,\n",
    "        \"nflows_activation_func\": F.elu,\n",
    "        \"nflows_use_batch_norm\": True,\n",
    "        \"nflows_NSF_tail_bound\": 3\n",
    "    },\n",
    "    {\n",
    "        \"model\": NSF,\n",
    "        \"task_name\": \"slcp_distractors\",\n",
    "        \"num_samples\": 5000,\n",
    "        \"nflows_NSF_spline\": PiecewiseRationalQuadraticCouplingTransform,\n",
    "        \"nflows_num_transforms\": 3,#4\n",
    "        \"nflows_hidden_dim\": 128,\n",
    "        \"nflows_num_blocks\": 3,#5\n",
    "        \"early_stopping_patience\": 20,\n",
    "        \"epochs\": 1000,\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"batch_size\": 512,\n",
    "        \"scaler\": StandardScaler,\n",
    "        \"nflows_activation_func\": F.elu,\n",
    "        \"nflows_use_batch_norm\": True,\n",
    "        \"nflows_NSF_tail_bound\": 5,#3\n",
    "    },\n",
    "     {\n",
    "        \"model\": NSF,\n",
    "        \"task_name\": \"bernoulli_glm\",\n",
    "        \"num_samples\": 5000,\n",
    "        \"nflows_NSF_spline\": PiecewiseRationalQuadraticCouplingTransform,\n",
    "        \"nflows_num_transforms\": 5,\n",
    "        \"nflows_hidden_dim\": 32,\n",
    "        \"nflows_num_blocks\": 2,\n",
    "        \"early_stopping_patience\": 20,\n",
    "        \"epochs\": 50,\n",
    "        \"learning_rate\": 5e-4,\n",
    "        \"batch_size\": 256,\n",
    "        \"scaler\": StandardScaler,\n",
    "        \"nflows_activation_func\": F.elu,\n",
    "        \"nflows_use_batch_norm\": True,\n",
    "        \"nflows_NSF_tail_bound\": 6\n",
    "    },\n",
    "    {\n",
    "        \"model\": NSF,\n",
    "        \"task_name\": \"bernoulli_glm_raw\",\n",
    "        \"num_samples\": 5000,\n",
    "        \"nflows_NSF_spline\": PiecewiseRationalQuadraticCouplingTransform,\n",
    "        \"nflows_num_transforms\": 5,\n",
    "        \"nflows_hidden_dim\": 64,\n",
    "        \"nflows_num_blocks\": 2,\n",
    "        \"early_stopping_patience\": 20,\n",
    "        \"epochs\": 1000,\n",
    "        \"learning_rate\": 5e-4,\n",
    "        \"batch_size\": 128,\n",
    "        \"scaler\": StandardScaler,\n",
    "        \"nflows_activation_func\": F.elu,\n",
    "        \"nflows_use_batch_norm\": True,\n",
    "        \"nflows_NSF_tail_bound\": 6\n",
    "    },\n",
    "    {\n",
    "        \"model\": NSF,\n",
    "        \"task_name\": \"gaussian_mixture\",\n",
    "        \"num_samples\": 20000,\n",
    "        \"nflows_NSF_spline\": PiecewiseRationalQuadraticCouplingTransform,\n",
    "        \"nflows_num_transforms\": 6,\n",
    "        \"nflows_hidden_dim\": 128,\n",
    "        \"nflows_num_blocks\": 3,\n",
    "        \"early_stopping_patience\": 20,\n",
    "        \"epochs\": 1000,\n",
    "        \"learning_rate\": 5e-4,\n",
    "        \"batch_size\": 512,\n",
    "        \"scaler\": StandardScaler,\n",
    "        \"nflows_activation_func\": F.elu,\n",
    "        \"nflows_use_batch_norm\": True,\n",
    "        \"nflows_NSF_tail_bound\": 22\n",
    "    },\n",
    "    {\n",
    "        \"model\": NSF,\n",
    "        \"task_name\": \"two_moons\",\n",
    "        \"num_samples\": 20000,\n",
    "        \"nflows_NSF_spline\": PiecewiseRationalQuadraticCouplingTransform,\n",
    "        \"nflows_num_transforms\": 3,\n",
    "        \"nflows_hidden_dim\": 32,\n",
    "        \"nflows_num_blocks\": 2,\n",
    "        \"early_stopping_patience\": 20,\n",
    "        \"epochs\": 1000,\n",
    "        \"learning_rate\": 5e-4,\n",
    "        \"batch_size\": 512,\n",
    "        \"scaler\": StandardScaler,\n",
    "        \"nflows_activation_func\": F.elu,\n",
    "        \"nflows_use_batch_norm\": True,\n",
    "        \"nflows_NSF_tail_bound\": 8\n",
    "    },\n",
    "    {\n",
    "        \"model\": NSF,\n",
    "        \"task_name\": \"sir\",\n",
    "        \"num_samples\": 5000,\n",
    "        \"nflows_NSF_spline\": PiecewiseRationalQuadraticCouplingTransform,\n",
    "        \"nflows_num_transforms\": 8, \n",
    "        \"nflows_hidden_dim\": 256,\n",
    "        \"nflows_num_blocks\": 5, \n",
    "        \"early_stopping_patience\": 20,\n",
    "        \"epochs\": 50,\n",
    "        \"learning_rate\": 5e-4, \n",
    "        \"batch_size\": 512, \n",
    "        \"scaler\": StandardScaler,\n",
    "        \"nflows_activation_func\": F.elu, \n",
    "        \"nflows_use_batch_norm\": True, \n",
    "        \"nflows_NSF_tail_bound\": 12\n",
    "    },\n",
    "    {\n",
    "        \"model\": NSF,\n",
    "        \"task_name\": \"lotka_volterra\",\n",
    "        \"num_samples\": 5000,\n",
    "        \"nflows_NSF_spline\": PiecewiseRationalQuadraticCouplingTransform,\n",
    "        \"nflows_num_transforms\": 10, \n",
    "        \"nflows_hidden_dim\": 512, \n",
    "        \"nflows_num_blocks\": 4, \n",
    "        \"early_stopping_patience\": 20,\n",
    "        \"epochs\": 50,\n",
    "        \"learning_rate\": 1e-4, \n",
    "        \"batch_size\": 512, \n",
    "        \"scaler\": StandardScaler,\n",
    "        \"nflows_activation_func\": F.elu, \n",
    "        \"nflows_use_batch_norm\": True, \n",
    "        \"nflows_NSF_tail_bound\": 8 \n",
    "    }\n",
    "\n",
    "]\n",
    "\n",
    "models_MAF = [\n",
    "  {\n",
    "        \"model\": MAF,\n",
    "        \"task_name\": \"gaussian_linear_uniform\",\n",
    "        \"num_samples\": 5000,\n",
    "        \"nflows_MAF_transform\": MaskedAffineAutoregressiveTransform,\n",
    "        \"nflows_num_transforms\": 5,\n",
    "        \"nflows_hidden_dim\": 32,\n",
    "        \"nflows_num_blocks\": 4, \n",
    "        \"early_stopping_patience\": 20,\n",
    "        \"epochs\": 1000, \n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"batch_size\": 256,\n",
    "        \"scaler\": StandardScaler,\n",
    "        \"nflows_activation_func\": F.elu,\n",
    "        \"nflows_use_batch_norm\": True,\n",
    "        \"seed\": 0,\n",
    "        \"save_fig\": False,\n",
    "        \"save_generated_dataset\": False,\n",
    "        \"save_model\": False\n",
    "    },\n",
    "    {\n",
    "        \"model\": MAF,\n",
    "        \"task_name\": \"two_moons\",\n",
    "        \"num_samples\": 5000,\n",
    "        \"nflows_MAF_transform\": MaskedAffineAutoregressiveTransform,\n",
    "        \"nflows_num_transforms\":10,#10\n",
    "        \"nflows_hidden_dim\": 16,#16\n",
    "        \"nflows_num_blocks\": 2, #2\n",
    "        \"early_stopping_patience\": 20,\n",
    "        \"epochs\": 1000, \n",
    "        \"learning_rate\": 1e-3,#\n",
    "        \"batch_size\": 128,#\n",
    "        \"scaler\": MinMaxScaler,\n",
    "        \"nflows_activation_func\": F.elu,\n",
    "        \"nflows_use_batch_norm\": True,\n",
    "        \"seed\": 0,\n",
    "        \"save_fig\": False,\n",
    "        \"save_generated_dataset\": False,\n",
    "        \"save_model\": False\n",
    "    },\n",
    "     {\n",
    "        \"model\": MAF,\n",
    "        \"task_name\": \"bernoulli_glm\",\n",
    "        \"num_samples\": 5000,\n",
    "        \"nflows_MAF_transform\": MaskedAffineAutoregressiveTransform,\n",
    "        \"nflows_num_transforms\": 7,#6\n",
    "        \"nflows_hidden_dim\": 64,#64\n",
    "        \"nflows_num_blocks\": 10, #10\n",
    "        \"early_stopping_patience\": 20,\n",
    "        \"epochs\": 1000,\n",
    "        \"learning_rate\": 1e-3,#1e-4\n",
    "        \"batch_size\": 128,#128\n",
    "        \"scaler\": MinMaxScaler,\n",
    "        \"nflows_activation_func\": F.elu,\n",
    "        \"nflows_use_batch_norm\": True,\n",
    "        \"seed\": 0,\n",
    "        \"save_fig\": False,\n",
    "        \"save_generated_dataset\": False,\n",
    "        \"save_model\": False\n",
    "    },\n",
    "      {\n",
    "        \"model\": MAF,\n",
    "        \"task_name\": \"slcp\",\n",
    "        \"num_samples\": 5000,\n",
    "        \"nflows_MAF_transform\": MaskedAffineAutoregressiveTransform,\n",
    "        \"nflows_num_transforms\": 8,#8\n",
    "        \"nflows_hidden_dim\": 64,#64\n",
    "        \"nflows_num_blocks\": 10, #10\n",
    "        \"early_stopping_patience\": 20,\n",
    "        \"epochs\": 1000,\n",
    "        \"learning_rate\": 1e-4,#1e-4\n",
    "        \"batch_size\": 128,#128\n",
    "        \"scaler\": MinMaxScaler,\n",
    "        \"nflows_activation_func\": F.elu,\n",
    "        \"nflows_use_batch_norm\": True,\n",
    "        \"seed\": 0,\n",
    "        \"save_fig\": False,\n",
    "        \"save_generated_dataset\": False,\n",
    "        \"save_model\": False\n",
    "    },\n",
    "     {\n",
    "        \"model\": MAF,\n",
    "        \"task_name\": \"bernoulli_glm_raw\",\n",
    "        \"num_samples\": 5000,\n",
    "        \"nflows_MAF_transform\": MaskedAffineAutoregressiveTransform,\n",
    "        \"nflows_num_transforms\": 9,#6\n",
    "        \"nflows_hidden_dim\": 64,#64\n",
    "        \"nflows_num_blocks\": 10, #10\n",
    "        \"early_stopping_patience\": 20,\n",
    "        \"epochs\": 1000,\n",
    "        \"learning_rate\": 1e-3,#1e-4\n",
    "        \"batch_size\": 128,#128\n",
    "        \"scaler\": MinMaxScaler,\n",
    "        \"nflows_activation_func\": F.elu,\n",
    "        \"nflows_use_batch_norm\": True,\n",
    "        \"seed\": 0,\n",
    "        \"save_fig\": False,\n",
    "        \"save_generated_dataset\": False,\n",
    "        \"save_model\": False\n",
    "    },\n",
    "      {\n",
    "        \"model\": MAF,\n",
    "        \"task_name\": \"gaussian_linear\",\n",
    "        \"num_samples\": 5000,\n",
    "        \"nflows_MAF_transform\": MaskedAffineAutoregressiveTransform,\n",
    "        \"nflows_num_transforms\": 3,\n",
    "        \"nflows_hidden_dim\": 8,\n",
    "        \"nflows_num_blocks\": 2,\n",
    "        \"early_stopping_patience\": 20,\n",
    "        \"epochs\": 1000,\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"batch_size\": 128,\n",
    "        \"scaler\": StandardScaler,\n",
    "        \"nflows_activation_func\": F.elu,\n",
    "        \"nflows_use_batch_norm\": True,\n",
    "        \"seed\": 0,\n",
    "        \"save_fig\": False,\n",
    "        \"save_generated_dataset\": False,\n",
    "        \"save_model\": False\n",
    "    },\n",
    "    {\n",
    "        \"model\": MAF,\n",
    "        \"task_name\": \"gaussian_mixture\",\n",
    "        \"num_samples\": 5000,\n",
    "        \"nflows_MAF_transform\": MaskedAffineAutoregressiveTransform,\n",
    "        \"nflows_num_transforms\":8,#8\n",
    "        \"nflows_hidden_dim\": 2,#4\n",
    "        \"nflows_num_blocks\": 8, #8\n",
    "        \"early_stopping_patience\": 20,\n",
    "        \"epochs\": 1000,\n",
    "        \"learning_rate\": 1e-3,#1e-3\n",
    "        \"batch_size\": 256,#128\n",
    "        \"scaler\": MinMaxScaler,\n",
    "        \"nflows_activation_func\": F.elu,\n",
    "        \"nflows_use_batch_norm\": True,\n",
    "        \"seed\": 0,\n",
    "        \"save_fig\": False,\n",
    "        \"save_generated_dataset\": False,\n",
    "        \"save_model\": False\n",
    "    },\n",
    "    {\n",
    "        \"model\": MAF,\n",
    "        \"task_name\": \"sir\",\n",
    "        \"num_samples\": 5000,\n",
    "        \"nflows_MAF_transform\": MaskedAffineAutoregressiveTransform,\n",
    "        \"nflows_num_transforms\":10,#10\n",
    "        \"nflows_hidden_dim\": 16,#8\n",
    "        \"nflows_num_blocks\": 4,#4\n",
    "        \"early_stopping_patience\": 20,\n",
    "        \"epochs\": 1000,\n",
    "        \"learning_rate\": 1e-3,#\n",
    "        \"batch_size\": 128,#\n",
    "        \"scaler\": MinMaxScaler,\n",
    "        \"nflows_activation_func\": F.elu,\n",
    "        \"nflows_use_batch_norm\": True,\n",
    "        \"seed\": 0,\n",
    "        \"save_fig\": False,\n",
    "        \"save_generated_dataset\": False,\n",
    "        \"save_model\": False\n",
    "    },\n",
    "    {\n",
    "        \"model\": MAF,\n",
    "        \"task_name\": \"lotka_volterra\",\n",
    "        \"num_samples\": 5000,\n",
    "        \"nflows_MAF_transform\": MaskedAffineAutoregressiveTransform,\n",
    "        \"nflows_num_transforms\":8,#10\n",
    "        \"nflows_hidden_dim\": 64,#8\n",
    "        \"nflows_num_blocks\": 10,#4\n",
    "        \"early_stopping_patience\": 20,\n",
    "        \"epochs\": 1000,\n",
    "        \"learning_rate\": 1e-3,#\n",
    "        \"batch_size\": 128,#\n",
    "        \"scaler\": MinMaxScaler,\n",
    "        \"nflows_activation_func\": F.elu,\n",
    "        \"nflows_use_batch_norm\": True,\n",
    "        \"seed\": 0,\n",
    "        \"save_fig\": False,\n",
    "        \"save_generated_dataset\": False,\n",
    "        \"save_model\": False\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for task in models_MAF:\n",
    "    for num_samples in [20000,10000,5000]:\n",
    "        for i in range(0,5):\n",
    "            if i == 0 and num_samples == 20000:\n",
    "                torch.cuda.empty_cache()\n",
    "                run_model(\n",
    "                    model = task[\"model\"],\n",
    "                    task_name = task[\"task_name\"],\n",
    "                    num_samples = num_samples,\n",
    "                    nflows_MAF_transform = task[\"nflows_MAF_transform\"],\n",
    "                    nflows_num_transforms = task[\"nflows_num_transforms\"],\n",
    "                    nflows_hidden_dim = task[\"nflows_hidden_dim\"],\n",
    "                    nflows_num_blocks = task[\"nflows_num_blocks\"],\n",
    "                    early_stopping_patience = task[\"early_stopping_patience\"],\n",
    "                    epochs = 1000, \n",
    "                    learning_rate = task[\"learning_rate\"],\n",
    "                    batch_size = task[\"batch_size\"],\n",
    "                    scaler = task[\"scaler\"],\n",
    "                    nflows_activation_func = task[\"nflows_activation_func\"],\n",
    "                    nflows_use_batch_norm = task[\"nflows_use_batch_norm\"],\n",
    "                    seed = i,\n",
    "                    save_fig = True,\n",
    "                    save_generated_dataset = True,\n",
    "                    save_model = False\n",
    "                )\n",
    "            else:\n",
    "                torch.cuda.empty_cache()\n",
    "                run_model(\n",
    "                    model = task[\"model\"],\n",
    "                    task_name = task[\"task_name\"],\n",
    "                    num_samples = num_samples,\n",
    "                    nflows_MAF_transform = task[\"nflows_MAF_transform\"],\n",
    "                    nflows_num_transforms = task[\"nflows_num_transforms\"],\n",
    "                    nflows_hidden_dim = task[\"nflows_hidden_dim\"],\n",
    "                    nflows_num_blocks = task[\"nflows_num_blocks\"],\n",
    "                    early_stopping_patience = task[\"early_stopping_patience\"],\n",
    "                    epochs = 1000, \n",
    "                    learning_rate = task[\"learning_rate\"],\n",
    "                    batch_size = task[\"batch_size\"],#\n",
    "                    scaler = task[\"scaler\"],\n",
    "                    nflows_activation_func = task[\"nflows_activation_func\"],\n",
    "                    nflows_use_batch_norm = task[\"nflows_use_batch_norm\"],\n",
    "                    seed = i,\n",
    "                    save_fig = False,\n",
    "                    save_generated_dataset = True,\n",
    "                    save_model = False\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
